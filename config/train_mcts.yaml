# @package _global_
# config/train_mcts.yaml

defaults:
  - _self_ # Allows values defined here to be defaults
#  - override hydra/job_logging: colorlog # Optional: for nicer logging
#  - override hydra/hydra_logging: colorlog # Optional: for nicer logging

hydra:
  run:
    dir: outputs/mcts_train/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/mcts_train/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

# Target the main Config dataclass
_target_: MCTS.config_schema.Config

network:
  # Target the specific NetworkConfig dataclass
  _target_: MCTS.config_schema.NetworkConfig
  # Values here override defaults in the dataclass
  input_channels: 119  # 8-step AlphaZero history (112) + 7 meta planes for Legacy board
  dim_piece_type: 16
  board_size: 8
  num_residual_layers: 0
  num_filters: [32, 32, 32, 32, 32, 32, 32]
  conv_blocks_channel_lists: []
  action_space_size: 4672
  num_pieces: 32
  policy_head_out_channels: 4 # Only used for action space size 4672
  value_head_hidden_size: 64
  action_space_mode: "4672"  # Use 4672 action space with LegacyChessBoard

# New Env section
env:
  _target_: MCTS.config_schema.EnvConfig
  type: chess  # "chess" or "gomoku" - specifies which environment to use
  observation_mode: vector
  render_mode: rgb_array # Set to null or remove for no rendering
  save_video_folder: './videos' # Set to null or remove for no video saving

mcts:
  _target_: MCTS.config_schema.MCTSConfig
  iterations: 1
  c_puct: 1.41
  temperature_start: 1.25
  temperature_end: 0.5
  temperature_decay_moves: 40
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  

optimizer:
  _target_: MCTS.config_schema.OptimizerConfig
  type: Adam
  learning_rate: 0.1
  # momentum: 0.9 # Not needed for Adam default
  weight_decay: 1e-4

training:
  _target_: MCTS.config_schema.TrainingConfig
  replay_buffer_size: 8192
  device: auto # If device is cpu and multiprocessing is false and render_mode is not null, you can see the pygame window
  num_training_iterations: 1000
  training_epochs: 50
  batch_size: 64
  use_multiprocessing: true # Set to false for sequential self-play
  self_play_workers: null # Example: Use 8 parallel workers for self-play games
  self_play_games_per_epoch: 24
  max_game_moves: 200
  checkpoint_dir: ./checkpoints
  checkpoint_dir_load: null # If set, load checkpoints from here; otherwise use checkpoint_dir
  save_interval: 10
  initial_board_fen: rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1
  progress_bar: true
