# @package _global_
# config/train_mcts.yaml

defaults:
  - _self_ # Allows values defined here to be defaults
#  - override hydra/job_logging: colorlog # Optional: for nicer logging
#  - override hydra/hydra_logging: colorlog # Optional: for nicer logging

hydra:
  run:
    dir: outputs/mcts_train/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/mcts_train/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}

# Target the main Config dataclass
_target_: MCTS.config_schema.Config

network:
  # Target the specific NetworkConfig dataclass
  _target_: MCTS.config_schema.NetworkConfig
  # Values here override defaults in the dataclass
  input_channels: 119  # 8-step AlphaZero history (112) + 7 meta planes for Legacy board
  dim_piece_type: 16
  board_size: 8
  num_residual_layers: 16
  initial_conv_block_out_channels: [128]
  residual_blocks_out_channels: [[128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128], [128]]
  action_space_size: 4672
  num_pieces: 32
  value_head_hidden_size: 512
  # Policy head structure
  policy_linear_out_features: [4672] # e.g., [1024, 512, 4672]; last must equal action_space_size
  conv_bias: false # Whether to use bias in convolutional layers

# New Env section
env:
  _target_: MCTS.config_schema.EnvConfig
  type: chess  # "chess" or "gomoku" - specifies which environment to use
  observation_mode: vector
  render_mode: rgb_array # Set to null or remove for no rendering
  save_video_folder: './videos' # Set to null or remove for no video saving
  history_steps: 8

mcts:
  _target_: MCTS.config_schema.MCTSConfig
  c_puct: 1.41
  iterations: 100
  temperature_start: 1.0
  temperature_end: 0.1
  temperature_decay_moves: 30
  dirichlet_alpha: 0.3
  dirichlet_epsilon: 0.25
  batch_size: 32  # Maximum batch size for MCTS (dynamic batching will optimize based on GPU memory)
  

optimizer:
  _target_: MCTS.config_schema.OptimizerConfig
  type: Adam
  learning_rate: 1e-4
  # momentum: 0.9 # Not needed for Adam default
  weight_decay: 1e-4

training:
  _target_: MCTS.config_schema.TrainingConfig
  replay_buffer_size: 8192
  device: auto # If device is cpu and multiprocessing is false and render_mode is not null, you can see the pygame window
  num_training_iterations: 50
  num_training_steps: 100
  batch_size: 64
  use_multiprocessing: true # Set to false for sequential self-play
  self_play_workers: null # Example: Use 8 parallel workers for self-play games
  self_play_steps_per_epoch: 1024
  continual_training: true
  continual_queue_maxsize: 64
  max_game_moves: 100
  checkpoint_dir: ./checkpoints
  checkpoint_dir_load: null # If set, load checkpoints from here; otherwise use checkpoint_dir
  game_history_dir: ./game_history # Directory to save game history files. Set to null to disable.
  initial_board_fen:
    # 1. Starting position (50% weight, equal position)
    "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1":
      weight: 0.5
      quality: "equal"
    # Endgame positions (20 common endgames, 2.5% each)
    # 2. King and Queen vs King (basic checkmate) - winning for white
    "8/8/8/4k3/8/3K4/Q7/8 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 3. King and Rook vs King (rook checkmate) - winning for white
    "8/8/8/3k4/8/3K4/R7/8 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 4. King and two Bishops vs King - winning for white
    "8/8/8/3k4/8/3K4/1BB5/8 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 5. King, Bishop and Knight vs King (difficult checkmate) - winning for white
    "8/8/8/4k3/8/3K4/8/2B1N3 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 6. King and Pawn vs King (passed pawn, white to move) - winning for white
    "8/8/8/4k3/8/4P3/4K3/8 w - - 0 1":
      weight: 0.025
      quality: "equal"
    # 7. Rook and Pawn vs Rook (Lucena position) - losing for white
    "8/8/8/8/8/4P3/4K3/6kr w - - 0 1":
      weight: 0.025
      quality: "losing"
    # 8. Queen vs Rook (queen advantage) - winning for white
    "8/8/8/4k3/8/3K4/Q7/7r w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 9. Fried Liver Attack - black to move
    "r1bqkb1r/pppp1ppp/2n2n2/4p1N1/2B1P3/8/PPPP1PPP/RNBQK2R b KQkq - 5 4":
      weight: 0.025
      quality: "equal"
    # 10. Blackburne Shilling Gambit - winning for black
    "r1b1kbnr/pppp1Npp/8/8/2BnP3/8/PPPP1PqP/RNBQK2R w KQkq - 0 6":
      weight: 0.025
      quality: "losing"
    # 11. White trying Scholar's Mate against black's King and Queen - equal
    "r1bqkbnr/pppp1ppp/2n5/4p2Q/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 3 3":
      weight: 0.025
      quality: "equal"
    # 12. Petrov's Defense: Classical, Stafford Gambit - winning for black
    "r1bBk2r/ppp2ppp/2p5/2b5/4n3/3P4/PPP2PPP/RN1QKB1R b KQkq - 0 7":
      weight: 0.025
      quality: "losing"
    # 13. Scotch Gambit - Delayed Sarratt Variation - winning for white
    "r1bqkbnr/pppp2p1/2n4p/8/2BpP3/8/PPP2PPP/RNBQK2R w KQ - 2 7":
      weight: 0.025
      quality: "winning"
    # 14. King and two Rooks vs King - winning for white
    "8/8/8/3k4/8/3K4/6RR/8 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 15. Initial setup with kings, pawns, and rooks only (not moved yet)
    "r3k2r/ppp2ppp/8/8/8/8/PPP2PPP/R3K2R w KQkq - 0 1":
      weight: 0.025
      quality: "equal"
    # 16. King, Knight and Pawn vs King and Queen - winning (knight can fork, pawn makes it winning)
    "8/8/8/4k3/8/3KP3/4N3/7q w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 17. King and two Knights vs King - winning for white (replaces insufficient material)
    "8/8/8/3k4/8/3K4/NN6/8 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 18. Rook vs Queen (skewer) - winning for white, rook can skewer queen and king (queen between rook and king, king cannot take rook after)
    "4q3/8/8/4k3/8/3K4/8/1R6 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 19. Rook vs Bishop (material imbalance) - winning for white
    "8/8/8/4k3/8/3K4/R7/4b3 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 20. Rook vs Knight (material imbalance) - winning for white
    "8/8/8/4k3/8/3K4/R7/5n2 w - - 0 1":
      weight: 0.025
      quality: "winning"
    # 21. King and Pawn vs King and Pawn (opposition) - equal
    "8/8/8/8/4p3/6K1/4P3/6k1 w - - 0 1":
      weight: 0.025
      quality: "equal"
  progress_bar: true
  max_training_time_seconds: null # Maximum training time in seconds. At the end of each iteration, predicts total elapsed time after next iteration and stops if it would exceed this limit. Set to null to disable. Example: 3600 for 1 hour, 7200 for 2 hours.
  draw_reward: null # Fixed reward value for draws. Set to null to use draw_reward_table
  draw_reward_table:
    THREEFOLD_REPETITION:
      winning: -0.9
      equal: -0.3
      losing: 0.2
    FIVEFOLD_REPETITION:
      winning: -0.9
      equal: -0.3
      losing: 0.2
    STALEMATE:
      winning: -0.9
      equal: -0.25
      losing: 0.4
    MAX_MOVES:
      winning: -0.4
      equal: -0.2
      losing: 0.3
    INSUFFICIENT_MATERIAL:
      winning: -0.4
      equal: -0.05
      losing: 0.4
